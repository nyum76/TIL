# 내일배움캠프 29일차 TIL

## LLM (Large Language Model)
: 대규모 데이터로 학습을 많이 시킨 큰 인공지능
### 동작 원리
1. 학습 : 대규모 텍스트 데이터셋 사용
2. 추론 : 이전 맥락 기억해서 추론을 통한 답변 생성
3. 미세조정 : 특정 용도에 맞춰 추가학습

### 특징 
* 랜덤성 (Randomness) : 같은 질문이라도 매번 동일한 답변 X
  * `temperature`매개변수가 랜덤성에 영향
    * 높을수록 창의적이고 예측하기 어려운 답변
    * 낮을수록 일관되고 예측 가능한 답변
* 조건성 (Conditioning)

## OpenAI Playground
: 프롬프트 엔지니어링 실습하고 AI 모델 동작 체험 플랫폼
* 모델 선택
* temperature : 모델 랜덤성 조정
  * 0.0 : 최소 랜덤성
  * 1.0 : 최대 랜덤성
* 토큰 길이 : 텍스트 의미 단위
  * 짧은 응답 예시 : 50 토큰
  * 긴 응답 예시 : 200 토큰
* Top - p : 응답 다양성을 제어하는 또 다른 파라미터
  * 1.0 : 모든 가능한 답변 고려 -> 다양한 응답
  * 0.5 : 확률 상위 50% 해당 답변 선택, 더 집중된 응답 생성
* 프롬프트 형식 : (Stop Sequences) : 프롬프트 종료 위한 특정 단어나 기호 설정

## 프롬프트 엔지니어링
: LLM 이 사용자가 원하는 답변을 주도록 프롬프트를 개선하는 작업
  * 프롬프트란? : 사용자가 언어 모델을 설정하거나 입력하는 모든 텍스트
* 역할
  * User : 모델과 대화하는 주체
  * Assistant : User의 질문에 답변을 제공
  * System : 대화 기본 규칙과 Assistant 성격 조정
* 기본 원칙
  * 명확하고 구체적인 요청
  * 정보 제공
  * 제약조건 명시
  * 복잡한 작업 분할
### 프롬프팅 기법
#### Shot 계열 프롬프팅 기법
* Zero Shot : 예제 0개
* One Shot : 예제 1개
* Few Shot : 예제 여러 개
-> Shot 을 많이 줄 수록 원하는 방향으로 답변 유도 확률 증가

### Persona 기법
: Act As, AI 에게 특정한 역할을 부여하는 프롬프트

### CoT 기법
: LLM 의 논리적 추론 한계를 극복하기 위해 단계별로 추론 과정을 설명하도록 모델에게 유도. 중간 추론 단계 명시
* 자동화된 CoT
* 직접 중간 과정 넣기 ( Shot 기법 + CoT 기법 )

### 대화를 활용한 프롬프팅 기법
* 정보 제공하기
  * 정확한 답변 유도
  * 모르는 데이터 학습
* 대화로 개선하기
  * 대화형 시스템은 이전 대화를 기억함
    * 이전 대화를 얼마나 기억할지
    * 전체 또는 핵심정보만 기억할지 설정 필요

### 형식 지정 기법
: 인공지능이 잘 이해하는 구조화된 문서 형식
* Markdown
* JSON
* 특수기호

## Vector DB
: 데이터를 벡터 형식으로 저장하고, 이를 효율적으로 검색할 수 있는 데이터베이스
* 임베딩 (Embedding) : 텍스트나 이미지 데이터 등을 벡터화

## RAG 
: LLM 과 검색시스템 결합
* 동작 원리
  1. 검색 단계 (Retrieval) : 사용자 질문 -> Vector DB 에서 유사 데이터 검색
  2. 생성 단계 (Generation) : 검색된 문서를 LLM 에 전달 -> 자연스러운 답변 생성


## 텍스트 처리
1. 토큰화 : 텍스트를 특정 기준으로 나눔으로써 모델이 이해할 수 있는 형태로 변환
   1. 단어단위 
      1. 장점 : 간단하고 빠름
      2. 단점 : 한국어 같은 언어에서 명확 X, 복잡한 분석 불리
   2. 서브워드단위
      1. 장점 : 희귀단어, 새 단어에 유용, 어휘크기 줄임
      2. 단점 : 분할 과정 복잡, 일부 단어는 분할시 의미 왜곡 가능성 존재
   3. 문장단위
      1. 장점 : 문맥 이해 유용
      2. 단점 : 긴 문장 경계 탐지 어려움
2. 정규화 : 텍스트를 일관성 있는 표준화된 형식으로 변환
   1. 소문자 변환
   2. 불필요한 기호 제거
3. 어간. 표제어 추출
4. 불용어 제거
   1. 장점 : 중요 단어에 모델 집중 -> 학습 효과 증가
   2. 단점 : 불용어가 중요한 의미를 갖는 문장에서 의미 왜곡
5. 문장 분리. 길이 조정
6. 형태소 분석

## 임베딩 (Embedding)
: 텍스트 데이터를 컴퓨터가 이해할 수 있는 벡터 (숫자 배열)로 변환하는 과정
* 기법
  * BoW : 빈도 기준
    * 장점 : 간단 문서 분류, 텍스트 분석 유용
    * 단점 : 단어 순서, 문맥 고려 X -> 의미 분석 한계
  * TF - IDF : 단어 빈도. 중요도 고려
    * 장점 : 문서간 중요 단어 구분, 희소성 문제 일부 해결
    * 단점 : 문맥 고려 X -> 의미 분석 한계
  * Word2Vec, Glove : 문맥 고려해 임베딩
  * Transfer 기반 임베딩
    * BERT
    * GPT
