# 내일배움캠프 18일차 TIL
## 파이썬 코드카타 DAY10
```py
# 점의 위치 구하기
def solution(dot):
    answer=0
    if (dot[0]<0)&(dot[1]<0):
        answer=3
    elif (dot[0]>=0)&(dot[1]<0):
        answer=4
    elif (dot[0]>=0)&(dot[1]>=0):
        answer=1
    else:
        answer=2
    return answer

# 2차원으로 만들기
def solution(num_list, n):
    answer = []
    for i in range(0,len(num_list),n):
        answer.append(num_list[i:i+n])
    return answer

# 공 던지기
def solution(numbers, k):
    return numbers[2*(k-1)%len(numbers)]

# 배열 회전시키기
def solution(numbers, direction):
    answer = []
    if direction=="right":
        answer.append(numbers[-1])
        answer.extend(numbers[:-1])
    else:
        answer.extend(numbers[1:])
        answer.append(numbers[0])
            
    return answer
```
---
## 필수 팀과제
```py
# 데이터셋 불러오기
import seaborn as sns
import numpy as np
import pandas as pd

titanic=sns.load_dataset('titanic')

# 3-1 결측치 처리 : Age 결측치는 중앙값(median), Embarked 결측치는 최빈값(mode)으로 대체
titanic['age'].fillna(titanic['age'].median(), inplace=True)
# fillna(결측치를대체할값,inplace=True) 메서드 : 결측값 대체. inplace 옵션의 기본값은 False로, 이는 변경사항을 원본데이터프레임에 적용할지를 나타냄
titanic['embarked'].fillna(titanic['embarked'].mode()[0], inplace=True)

# 3-2 수치형으로 인코딩 : Sex에서 male=0, female=1, alive에서 yes=1, no=0 으로 변환
# embarked에서 C=0,Q=1,S=2로 변환 후, 그 결과를 head 로 확인
# map() 메서드 : 데이터 값 변환
titanic['sex']=titanic['sex'].replace({'male':0,'female':1})
titanic['alive']=titanic['alive'].replace({'yes':1,'no':0})
titanic['embarked']=titanic['embarked'].replace({'C':0,'Q':1,'S':1})

# 3-3 새로운 Feature 생성 : SibSip,Parch 를 통해 family_size 생성 후 head 로 확인
titanic['family_size']=titanic['sibsp']+titanic['parch']+1
# +1을 해주는 이유 : 각 승객의 가족 크기 계산시 그 승객 본인을 포함해야 하기 때문에

# 4-1 모델 학습 준비 : 학습에 필요한 feature 들과 target 을 분리 후 스케일링
# 학습에 필요한 feature : 'survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'family_size'
titanic=titanic[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'family_size']]
X=titanic.drop('survived',axis=1) # fearue
# 'survived' 열을 제외한 나머지 열을 X에 저장
y=titanic['survived'] # target
# 'survived' 열만 선택하여 target 생성 (모델이 예측할 생존 여부)
# 필요한 라이브러리 불러오기

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# test_size=0.2 : 전체 데이터의 20%를 평가용 데이터로 사용
# random_state=42 : 랜덤 시드를 사용해 동일한 데이터 분할과 초기화를 하기 위해 설정함

# 데이터 스케일링 : 각 특성의 값 범위를 비슷하게 조정해 모델 학습의 효율성을 높임
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
# fit() : 각 특성의 평균과 표준편차 계산
X_test = scaler.transform(X_test)
# fit 사용시 테스트 데이터의 정보가 모델 학습에 영향을 줄 수 있으므로,
```
![](/img/241025_replace.png)
* 변경사항 : 3-2 수치형으로 인코딩에서 .map 대신 .replace를 써야한다
  * 이유 : map은 기존값을 매핑해서 변환하므로 딕셔너리에 값이 존재하지 않을 시 맵핑이 불가능해 NaN을 반환하고, replace는 값을 바꿔주는 역할이라 값이 존재하지 않아도 기존 값을 그대로 유지해주므로
  * 참고 : [map 과 replace 의 차이](https://abluesnake.tistory.com/142#google_vignette)
* 변경사항 : 필수과제 4-3 모델학습 부분이 랜덤포레스트에서 의사결정 나무로 바뀜.
```py
# 4-3 Decision Tree  
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 모델 생성 및 학습
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)

# 예측
y_pred = model.predict(X_test)

# 평가
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
print(f"Confusion Matrix:\n{confusion_matrix(y_test, y_pred)}")
```
---
## 도전 팀과제 : 영화 리뷰 감성 분석
```py
# 1 데이터셋 불러오기
import pandas as pd

df = pd.read_csv("netflix_reviews.csv")

# shape  : 행과 열의 개수를 튜플로 반환
print("Shape of dataset :",df.shape)

print("Columns in the dataset : ",df.columns)
```
![](/img/241025_shape.png)
```py
# head() : 상단 5개 데이터
df.head()
```
![](/img/241025_head().png)
```py
# tail() : 하단 5개 데이터
df.tail()
```
![](/img/241025_tail().png)
```py
# 2 데이터 전처리
# 전처리 함수
def preprocess_text(text):
    if isinstance(text,float):
        return ""
    text = text.lower()
    text = re.sub(r'[^\w\s]','',text) # text 중 문자+띄어쓰기를 제외한 모든것을 없앰
    # re.sub(pattern,replace,text) : text 중 pattern에 해당하는 부분 replace 로 대체
    # r (raw string) : 원시문자열로, \n 등이 있을 때 사용하면 출력 등에서 줄바꿈 안하고 \n 도 글자로 포함해 출력
    text = re.sub(r'\d+','',text) # text 중 숫자가 하나 이상인 것 제거
    text = text.strip() # .strip() : 문자열 앞,뒤 공백 제거
    return text
```

---
## 기초 선형 대수 특강
데이터 종류
* 질적 데이터
  * 명목 척도 :순서나 크기의 개념이 없으며, 단순한 분류나 구분만 가능
  * 서열 척도 : 순서나 대소관계가 의미가 있지만, 비례관계를 나타내지 않음
    * 서열등급 등
* 양적 데이터  
  * 등간 척도 : 대소 관계와 함께 값들 간의 차이에 의미가 있는 데이터, 0의 값은 절대적이지 않고, 사람이 임의로 정한 기준임, 비율 비교 불가
    * 날짜와 시간
  * 비율 척도 : 절대적 0을 포함하며 비율 비교가 가능한 데이터로
    * 키, 몸무게, 거리
* 이산형 데이터 : 연속적 X, 정해진 범위 내 특정 값
  * 값이 하나하나 구분되는 변수, 주로 정수 값, 불연속적
* 연속형 데이터: 연속적, 범위 내 무한히 많은 값들   
  * 값이 연속적이여서 값 사이에 무한히 많은 세부적인 값 존재
중요성 
* 데이터 전처리
  * 질적 데이터 (명목, 서열척도)는 숫자로 변환해 모델에 입력
    * 명목 척도 : 원-핫 인코딩(하나만 1이다)
      * 예) 혈액형 - A(1,0,0,0), B(0,1,0,0), C(0,0,1,0), O(0,0,0,1)
        * 숫자를 1말고 다른 수를 쓸 시에 크기 순이 생겨서 문제가 생김
    * 서열 척도 : 라벨 인코딩
      * 예) 설문지 만족도 - 매우 좋음(5), 좋음(4), 보통(3), 나쁨(2), 매우 나쁨(1)
        * 대소관계가 있어서 숫자를 넣어도 됨
  * 양적 데이터 (등간, 비율 척도)는 숫자 그대로 사용 가능
    * 등간 척도 데이터는 비율 척도처럼 절대적 의미가 없기 때문에 주의
      * 비율 연산 피해야 함 : 값을 두배로 하거나, 나누기 연산은 의미가 없음
      * 정규화 : 0~1 사이의 정규화보다 표준화(평균0,표준편차1)이 적절 -> (X-최솟값)/(최댓값-최솟값)
      * 피처 엔지니어링 : 차이를 강조한 특징을 생성하는 것이 좋음
      * 분류 모델에 클래스로 사용 : 순서나 차이만을 반영하도록 데이터 변환
* 데이터 해석
  * 데이터 시각화
    * 질적 데이터 : 카테고리나 범주의 빈도와 비율 시각화
      * 막대그래프,파이차트,히트맵
데이터 중심지표 : 데이터의 대표적인 값
* 평균(mean) : 모든 값을 더한 후 데이터 개수로 나눈 값**(이상치에 민감)**
* 중앙값(Median) : 데이터 크기순 나열시 중앙에 위치한 값 **(이상치에 영향 덜 받음)**
* 최빈값(Mode) : 데이터에서 가장 자주 나타나는 값 **(이상치에 영향 덜 받음)**
  * 이산형 데이터나 범주형일 때 자주 사용
* 데이터 분포의 형태에 따른 중심지표
  * 대칭 : 데이터가 정규 분포처럼 좌우 대칭으로 나타나는 분포
  * 왼쪽 꼬리 : 데이터가 왼쪽으로 치우쳐 있을 대 나타나는 분포
  * 오른쪽 꼬리 : 데이터가 오른쪽으로 치우쳐 있을 때 나타나는 분포
* 중요성 : 데이터 전처리
  * 결측치, 이상치 대체
  * 데이터 표준화
    * 데이터 분포를 평균이 0, 표준편차가 1이 되도록 변환
    * 데이터의 단위나 범위를 같게 해줌
    * 데이터가 서로 다른 단위나 범위를 가질 경우, 학습이 왜곡될 수 있음
  * 모델 선택
    * 평균 중심의 데이터 (데이터가 대칭적)
      * 선형 모델 (선형 회구, SVM)
    * 중앙값 중심의 데이터 (데이터가 치우져 있거나 이상치가 많은 경우)
      * 비선형 모델(랜덤 포레스트)
    * 최빈값 중심의 데이터 : 데이터가 명목형인 경우나 이산형 데이터 
      * 주어진 데이터의 주변 이웃 중 가장 많이 나타나는 값 예측(K-최근접 이웃)
      * 이산형 결과 예측시(로지스틱 회귀)
      * 범주형 데이터 기반 분류(나이브 베이즈)

데이터 산포도 : 데이터가 평균이나 중앙값을 중심으로 얼마나 퍼져있는지
* 편차(Variance)
  * 각 데이터 값과 데이터 평균 사이의 **차이**
  * 모든 편차 더하면 0
* 분산(Variance) -> 편차의 음수를 제거하려고
  * 편차 제곱의 평균
* 표준편차(Standard Deviation)
  * 분산의 제곱근으로 단위가 원래 데이터와 같음
* 사분위수 범위(IQR)
  * 중간 50% 데이터의 범위를 나타내는 지표
  * 데이터의 1사분위수(Q1) 과 3사분위수 (Q3) 의 차이 (이상치에 영향을 덜 받음)
  * 수식 : IQR=Q3-Q1

데이터 상관 관계 : 두 변수 간의 관계를 나타냄. 하나의 변수 변화에 따라 다른 변수가 어떻게 변하는지
* 양의 상관 관계 : 비례관계 (키가 클수록 몸무게도 증가하는 경향)
* 음의 상관관계 : 반비례관계 (기온이 올라가면 히터 사용량 줄어듬)
* 무 상관관계 : 두 변수 간 일정한 관계가 없는 경우 (사람의 키와 IQ 사이에 특별한 상관관계 없음)
* 상관계수 : 상관관계의 정도를 수치화한 값
  * 피어슨 상관계수 한계점 : 주로 선형관계를 측정하기에 두 변수 간의 관계가 비선형일 경우 이를 제대로 반영하기 어려움
  * 중요성 : 특징 선택시 
확률과 확률 분포 (가능한 경우에 대한 각각의 확률)
* 확률 : 특정 사건이 발생하는 경우의 수를 전체 가능 경우의 수로 나눈 값
  * 수식 : P(A)=사건A가 발생하는 경우의 수/전체 가능한 경우의 수

--> 이 이후는 강의 보면서 주말에 정리

---
## 추가로 알아본 내용
* `.append() 메서드` : **단일** 요소를 자료형의 **맨 끝에 추가**
  * 사용법  : `컬렉션자료형이름.append(추가할요소)`
  * 여러 요소 추가 : extend() 메서드 사용
* 리스트 슬라이싱 
  *  `list[start:end:step]`
     *  start : 시작 인덱스(포함)
     *  end : 종료 인덱스(포함X)
     *  step : 간격 (기본값 1)
  * 예제
    ```py
    # 사용할 리스트 생성
    numbers=[0,1,2,3,4,5]
    # 기본 슬라이싱 
    print(numbers[1:4]) # [1,2,3]

    # start 생략 : 처음부터 n 까지
    print(numbers[:3]) # [0,1,2]

    # end 생략 : n 부터 끝까지
    print(numbers[3:]) # [3,4,5]

    # step 사용
    print(numbers[::2]) # [0,2,4]

    # 음수 인덱스 : 리스트 끝부터 계산
    print(numbers[-3:]) # [3,4,5]
    print(numbers[:-2]) # [0,1,2,3] : 끝부터 2개를 제외한 나머지

    # 역순 슬라이싱
    print(numbers[::-1]) # [5,4,3,2,1,0] : 리스트 전체 역순
    ```
* 데이터 확인
  * `.shape` : 행과 열의 개수 튜플로 반환
  * `.head()` : 상단 5개 데이터
  * `.tail()` : 하단 5개 데이터
  * `columns` : 열 출력
* 데이터 전처리
  * `isinstance()` : 파이썬 자료형 확인 함수
    * 사용법 : `isinstance(인스턴스,클래스/데이터타입)`
    * 인스턴스가 지정한 클래스/데이터 타입에 부합하면 True, 아니면 False
  * `.lower` : 소문자로 변환
    * `.upper()` : 대문자로 변환
    * `.islower()` : 소문자이면 True, 아니면 False 반환
    * `.isupper()` : 대문자이면 True, 아니면 False 반환
  * `re.sub(pattern, replace, text)` : text 중 pattern에 해당하는 부분을 replace 로 대체
    * [패턴의 종류 참고 글](https://jjuha-dev.tistory.com/entry/Python-%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D-resub%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%AC%B8%EC%9E%90%EC%97%B4-%EC%B9%98%ED%99%98%ED%95%98%EA%B8%B0)
  * `.strip()` : 문자열 앞, 뒤 공백 제거