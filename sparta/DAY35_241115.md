# 내일배움캠프 35일차 TIL

## 개인과제 : LLM RAG 를 활용한 챗봇 만들기
### 1. 사용환경 준비
1. 필요 라이브러리 설치 (터미널에서 진행)
```py
pip install python-dotenv langchain langchain-openai faiss-cpu pypdf
```
2. OPENAI_API_KEY 불러오기
```py
from dotenv import (
    load_dotenv,
)  # dotenv 모듈 : .env 파일을 읽고 여기서 정의된 환경 변수를 시스템의 환경변수로 설정함
import os

load_dotenv()  # .env 파일에서 환경 변수 로드

api_key = os.getenv(
    "OPENAI_API_KEY"
)  # 환경변수에서 OPENAI_API_KEY 의 값 가져와 api_key 변수에 저장
print(api_key)  # API KEY 가 제대로 입력됐는지 확인
```
### 2. 모델 로드하기
```py
from langchain_openai import ChatOpenAI
from langchain_core.messages import (
    HumanMessage,
)  # Messages 작성(사용자의 요구사항이나 질문)을 위한 모듈 import

# 모델 초기화
model = ChatOpenAI(model="gpt-4o-mini", openai_api_key=OPENAI_API_KEY)
```
### 3. 문서 로드하기
* PyPDFLoader : PDF 파일 로드하고 이를 문서로 변환.
```py
from langchain.document_loaders import PyPDFLoader

# PDF 파일 로드. 파일의 경로 입력
loader = PyPDFLoader(
    "/your/pdf/path.pdf"
)

# 페이지 별 문서 로드
docs = loader.load()

# 로드된 문서 출력
'''for doc in docs:
    print(doc.page_content)''' # 전체 다 출력하면 출력 결과 너무 길어지므로
print(docs[0].page_content) # 한 페이지만 출력
```
### 4. 문서 청크로 나누기
#### 4.0 Chunk VS Token
##### Chunk
: 문자나 단어 등의 더 큰 의미 단위로 텍스트를 나누는 방식. 문맥적 의미를 기준으로 나눈다
* 특징
  * 크기 : 문자수 (characters) 나 단어수 (words) 로 정의됨
  * 의미 단위 : 청크는 텍스트를 의미가 있는 단위로 나누는데 중점을 둠.
    * 문장 단위
    * 문단 단위
    * 구문 단위 등

##### Token
: 텍스트의 기본적인 처리단위. NLP 모델에서 텍스트를 벡터화 하거나 분석하기 전에 텍스트를 나누는 가장 작은 단위. 모델이 이해할 수 있는 기본적인 단위
* 토큰화 (Tokenization) : 텍스트를 단어, 구두점, 특수 문자 등으로 분할하는 과정
* 특징
  * 크기 : 고정되어 있지 않음. 단어, 하위 단어, 구두점 등 다양한 요소로 구성됨
  * 언어 모델의 기본 단위 : GPT 같은 언어 모델은 토큰을 입력 받아 처리함

#### 4.1 CharacterTextSplitter
Langchain 에서 제공하는 문서 분할 도구. 문자 단위로 텍스트를 나눔.
##### 4.1.1 CharacterTextSplitter 특징
* **고정된 청크 크기** : 텍스트를 동일한 크기로 나눔. 일관성 있는 처리에 유용
* **속도** : 단순한 방식 덕분에 처리 속도가 빠르고, 대규모 데이터셋을 처리할 때 효율적
* **단순성** : 구현이 간단. 복잡한 설정 없이 다양한 응용 프로그램에 쉽게 통합
* 중복 오버랩 (Overlap) : 각 청크 간 겹치는 부분을 두어 텍스트를 자연스럽게 나눌 수 있음. 중복을 추가해 나눠진 청크가 더 의미 있는 단위로 나뉘어 모델이 문맥을 더 잘 이해할 수 있음


##### 4.1.2 parameter
---
* `separator` : 텍스트를 나누는 기준을 설정
  * 기본값 : 공백 `' '`
---
* `chunk_size` : 각 분할된 청크의 최대 길이를 설정
  * `chunk_size=100` : 각 청크가 최대 100자 까지 포함됨을 의미
---
* `chunk_overlap` : 청크 간 곂치는 문자 수를 설정  -> 각 텍스트간 의미가 끊어지지 않도록 하기 위함
  * `chunk_overlap=10` : 각 청크가 이전 청크와 최대 10자 겹침
---
* `length_function` : 각 청크의 길이 계산 함수
  * `length_function=len` : 각 청크의 길이가 문자 수로 계산됨.
  * `length_function=lambda text: len(text.split())` : 단어 수로 텍스트 나눔
---
* `is_separator_regex` : separator 가 정규표현식 인지
  * `is_separator_regex=False`(기본값) : separator로 지정된 텍스트가 정확히 일치하는 부분에서 텍스트를 나눔
  *  `is_separator_regex=True` : separator 에 정규 표현식을 사용할 수 있음
     *  `separator=r'\n+'`를 사용하면 여러 줄 바꿈이 있더라도 이를 하나의 분할 기준으로 사용

```py
from langchain.text_splitter import CharacterTextSplitter

text_splitter = CharacterTextSplitter(
    separator="\n\n",  # 분할기준 : 두 줄 바꿈을 기준으로 텍스트 나누기
    chunk_size=100,  # 청크 크기 : 최대 100자
    chunk_overlap=10,  # 중복 오버랩 : 각 청크가 최대 10자 겹침
    length_function=len,  # 길이 계산 함수 : 문자 수 기준 (len())
    is_separator_regex=False,  # 구분자가 정규 표현식인지 여부 (False : 정확히 일치하는 구분자 기준)
)

splits = text_splitter.split_documents(docs)
```
#### 4.2 RecursiveCharacterTextSplitter
내용의 **문맥을 유지**하면서 텍스트를 관리 가능한 청크로 분할 하도록 하는 청킹 방식. 대량의 텍스트를 처리할 때 유용. 관련 정보들이 서로 인접하게 유지되므로 **가독성**과 **이해도**를 높이는데 효과적.
##### 4.2.1 RecursiveCharacterTextSplitter 특징
* **계층적 세분화** : 텍스트를 문맥에 나누어 의미가 각 청크 간에 보존됨
* **적응형 청크 크기** : 텍스트 내용에 따라 청크 크기가 달라질 수 있음. 길이가 다른 문단이 포함된 문서에 유용
* **문맥 보존** : 주변 텍스트를 고려해 청킹 과정 중 중요한 정보가 손실되는 것을 최소화 함
```py
from langchain.text_splitter import RecursiveCharacterTextSplitter

recursive_text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=100, # 각 청크 최대 100자 까지
    chunk_overlap=10, # 청크간 최대 10자 중복
    length_function=len, # 길이 계산 함수 : 문자 수 기준 (len())
    is_separator_regex=False, # 구분자가 정규 표현식인지 여부 (False : 정확히 일치하는 구분자 기준)
)

splits = recursive_text_splitter.split_documents(docs)
```
### 5. 벡터 임베딩 생성
```py
from langchain_openai import OpenAIEmbeddings

# OpenAI 임베딩 모델 초기화
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
```

## Q n A 
Q. 벡터 임베딩을 진행할 때 모델 초기화만 해도 되는 것인가?
A. 모델 초기화 후에 벡터 스토어에 저장할 때 벡터 임베딩을 진행한다.



## 오늘의 오류
![](/img/241115_api_key_error_1.png)
![](/img/241115_api_key_error_2.png)
### 오류 상황
LLM RAG 를 활용한 챗봇 구축하기 개인과제를 진행하던 도중, 
내 API KEY 를 잘 불러오고 문서를 청크단위로 나누는것 까지 성공했는데
벡터 임베딩을 생성하는 부분에서
`embeddings = OpenAIEmbeddings(model="text-embedding-ada-002)`
`OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable`
가 발생했다.

### 해결
* OpenAI 의 API 키는 `sk-` 로 시작하는데 오류 코드를 자세히 보면 `k-` 로 시작하는 것을 볼 수 있다.
* API KEY 를 잘못 입력해서 발생한 오류
* 그렇다면 왜 `.env` 파일에서 내 API 키로 바꿨을 때도 동일한 에러가 발생하였나?
  * `.env`파일에서 변경사항이 업데이트 되지 않았기 때문
  * 커널을 재시작하여 문제 해결됨
### 요약
* OpenAI 의 API KEY 는 `sk-`로 시작한다. 
* `.env`파일에서 환경 변수 변경시 적용하기 위해 **커널 재시작 필요**


## 회고
오늘은 개인과제 5번까지 진행 해봤는데 진행하면서도 코드랑 친하지 않다고 느껴져서 주말에 
[PDF 문서 기반 Q n A RAG 구축하기](https://www.youtube.com/watch?v=Ga6kqHVKo9g)
이 강의를 따라 해 볼 생각이다. 

그리고 코드에 대한 주석도 더 자세히 많이 붙여 놓고, 개인 과제를 다 만든 후에는 `pip freeze`를 사용하여
`requirements.txt` 파일로 패키지도 명시 해 놓고, README.md 파일에도 설명을 써 놓을 계획이다.

더 완벽하게 하기 위해 이전에 수행했던 과제에 대한 피드백을 보고 체크리스트를 만들어 점검해 볼 예정이다.