# 내일배움캠프 33일차 TIL
## API KEY 관리
* API KEY 를 하드코딩으로 코드에 포함시킬 수도 있지만,
* 하드코딩시 API KEY 가 노출되면 폭탄 요금을 맞을 수도 있다!!
![](/img/my_money_TT.JPG)
* 따라서, **API KEY 를 관리**하는 것은 **매우 중요**하다
* 관리 방법
  1. 환경 변수로 관리
  2. .env 파일 등 별도의 파일에 기재

### .env 파일로 OpenAI API KEY 관리하기
* `.env`파일 생성
  1. 해당 프로젝트의 폴더 안에 `.env`파일 생성
![](/img/241113_dotenv.png)
  1. `.env` 파일 내에 키-값 쌍 형태로 자신의 OPENAI_API_KEY 를 입력
![](/img/241113_openaikey.png) 
* `.env `파일 활용
  1. `pyton-dotenv`패키지 설치
     1. 터미널에 `pip install python-dotenv`

  2. `python-dotenv` 패키지 import
  3. `os` 의 `getenv` 를 활용해 `OPENAI_API_KEY` 불러오기
```py
from dotenv import load_dotenv
import os

load_dotenv()  # .env 파일에서 환경 변수 로드

api_key = os.getenv("OPENAI_API_KEY")
print(OPENAI_API_KEY) # API KEY 가 제대로 입력됐는지 확인
```
* **`.env` 파일을 `.gitignore` 파일에 추가**
  * `.env` 파일이 Git 에 commit 되지 않도록 꼭 설정해주자
![](/img/241113_gitignoredotenv.png)

---
## Prompt Engineering
* LLM에 접근하기 가장 기본적인 방법 
* 직관적 (사용이 간단함)
* 지침을 주는 것과 유사
* prompt를 사용할 때, 모델이 어떤 정보를 주면 좋겠는지 모델에게 전달
* 좋은 출력결과를 얻기 위해 어떻게 올바르게 질문하는지 배우는 것
![](/img/241113_prompt.jpeg)
* 모델이 학습을 통해 얻은 지식만으로 답변하므로 
  * 모델에게서 얻을 수 있는 것엔 한계가 있다.
#### Prompt 장점
* 쉬운 사용
* 저렴한 비용 : 사전 학습된 모델을 사용하므로 파인튜닝과 비교했을 시 
* 빠른 적용
#### Prompt 단점
* 프롬프트의 표현 방식에 따라 답변이 천차만별일 수 있다
* **모델 지식의 한계** : 최신 자료나 학습하지 않은 정보에 대해서는 답변이 부정확하다
---
## Fine-tuning
* **사전학습된 언어 모델을 사용**해 **새롭거나 특별한 무언가를 학습**하도록 만드는 것
* 마치 앱이나 폰이 더 향상되도록 **업데이트**를 하는 것과 비슷하다
* 파인 튜닝에서 모델은 모든것을 적절히 배우기위해 엄청 **많은 새로운 정보와 시간**을 필요로 한다
* 파인 튜닝은 엄청난 컴퓨팅 파워와 시간을 필요로 하기에, 큰 자금적 요소가 필요하다.
* 하지만 **언어 모델이 특별한 주제에 대해 잘 이해하기를 원한다면** 파인튜닝이 적절하다.
* 특정한 주제에 대한 전문가가 되도록 모델을 학습시키는 것이다.


#### Fine-tuning 장점
* **맞춤화**
* 정확도 향상
* 적응성

#### Fine-tuning 단점
* 비용 : 컴퓨팅 과 시간 등의 자원을 필요로 하므로 비용적 측면에서 prompt 보다 비싸다
* 잘 정리된 데이터 필요
---
## RAG
(Retrieval Augmented Generation)
* LLM 과 지식을 합친 개념
* 모델이 답변을 생성할 때 이와 관련 있는 정보를 지식에서 찾고, 이를 바탕으로 답변을 생성한다.
* 모델이 정보의 도서관을 빠르게 확인하고 가장 최고의 답변을 주는 것과 같다
* 모델이 기존에 배운 주제보다 더 넓은 범위를 포함하는 최신 정보에 대한 답변을 원할 때 유용하다
* **Vector DB** : RAG의 비용과 속도, 응답의 질에 매우 큰 영향을 미치는 요소로 이전에 비유한 정보의 도서관 역할을 한다.


#### RAG 장점
* 다양한 정보
* Prompt Engineering의 편리함, fine-tuning의 맞춤화 장점을 제공한다

#### RAG 단점
* 복잡함 : LLM과 검색 시스템간의 통합이 필요
* 데이터 의존성

## Prompting vs Fine-tuning vs RAG
![](/img/241113_RAG_Finetuning_Prompting.png)
[참고 링크](https://medium.com/@myscale/prompt-engineering-vs-finetuning-vs-rag-cfae761c6d06)